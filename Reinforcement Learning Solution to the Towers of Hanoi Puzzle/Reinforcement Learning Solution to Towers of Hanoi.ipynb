{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Solution to the Towers of Hanoi Puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from IPython.display import display, clear_output\n",
    "import random\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid moves is a generic code for as much no of discs as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def printState(state):\n",
    "    for i in state:\n",
    "        for j in i:\n",
    "            print(j)\n",
    "    print('------------')\n",
    "    \n",
    "def validMoves(state):\n",
    "    move = [] \n",
    "    count1 = 1\n",
    "    for i in state:\n",
    "        if i == []:\n",
    "            count1 = count1 + 1\n",
    "            continue\n",
    "        else:\n",
    "            first = i[-1]\n",
    "        count = 1\n",
    "        for locations in state:\n",
    "            #print(count)\n",
    "            if locations == i:\n",
    "                count = count +1\n",
    "                continue\n",
    "            else:\n",
    "                if locations == []:\n",
    "                    move.append([count1,count])\n",
    "                else:\n",
    "                    if locations[-1]<first:\n",
    "                        count = count + 1\n",
    "                        continue\n",
    "                    else:\n",
    "                        move.append([count1,count])\n",
    "            count = count +1\n",
    "        count1 = count1 +1\n",
    "    return(move)\n",
    "\n",
    "def makeMove(state, move):\n",
    "    tempstate = copy.deepcopy(state)\n",
    "    #print(state)\n",
    "    #print(move)\n",
    "    #print(move[0])\n",
    "    element = state[move[0]-1][0]\n",
    "    del tempstate[move[0]-1][0]\n",
    "    #print(tempstate[move[0]][0])\n",
    "    tempstate[move[1]-1].insert(0,element)\n",
    "    return(tempstate)\n",
    "                \n",
    "def stateMoveTuple(state, move):\n",
    "    tempmove = copy.deepcopy(move)\n",
    "    temp = []\n",
    "    for st in state:\n",
    "        \n",
    "        if st != []:\n",
    "            temp.append(tuple(st))\n",
    "            #print(temp)\n",
    "        else:\n",
    "            temp.append(tuple())\n",
    "    #print(temp)\n",
    "    return(tuple([tuple(temp)]) + tuple([tuple(tempmove)]))\n",
    "\n",
    "\n",
    "def epsilonGreedy(epsilon, Q, state):\n",
    "    validMove = validMoves(state)\n",
    "    if np.random.uniform() < epsilon:       \n",
    "        return validMove[randint(0, len(validMove)-1)]\n",
    "    else:\n",
    "        # Greedy Move\n",
    "        Qs = []\n",
    "        for m in validMove:\n",
    "            Qs.append(Q.get(stateMoveTuple(state,m), -1))\n",
    "        #Qs = np.array([Q.get(stateMoveTuple(state, m), 0) for m in validMove]) \n",
    "        return validMove[np.argmax(np.asarray(Qs))]\n",
    "\n",
    "    \n",
    "def winner(state):\n",
    "    Win = [[], [], [1,2,3]]\n",
    "    if state == Win:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainQ(nRepetitions, learningRate, epsilonDecayFactor, validMoves, makeMove):\n",
    "    global Q    \n",
    "    maxGames = nRepetitions\n",
    "    rho = learningRate\n",
    "    epsilonDecayRate = epsilonDecayFactor\n",
    "    epsilon = 1\n",
    "    Q = {}   \n",
    "    Stepstogoal = []\n",
    "    for nGames in range(maxGames):\n",
    "        epsilon *= epsilonDecayRate\n",
    "        step = 0\n",
    "        state = [[1,2,3], [], []] #  start state\n",
    "        done = False\n",
    "        showMoves = False\n",
    "        while not done:        \n",
    "            step += 1\n",
    "            move = epsilonGreedy(epsilon, Q, state)\n",
    "            stateNew = copy.deepcopy(state)\n",
    "            stateNew = makeMove(state,move) \n",
    "            if winner(stateNew):\n",
    "                Q[stateMoveTuple(state, move)] = 0\n",
    "                done = True\n",
    "            if stateMoveTuple(state, move) not in Q:\n",
    "                Q[stateMoveTuple(state, move)] = -1  # initial Q value for new state,move\n",
    "            if step > 1:\n",
    "                Q[stateMoveTuple(stateOld, moveOld)] += rho * (-1+Q[stateMoveTuple(state, move)] - Q[stateMoveTuple(stateOld, moveOld)])\n",
    "            stateOld, moveOld = state, move \n",
    "            state = stateNew\n",
    "        Stepstogoal.append(step)\n",
    "    return Q,Stepstogoal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testQ(Q, maxSteps, validMovesF, makeMoveF):\n",
    "    done = False\n",
    "    state = [[1,2,3], [], []] #  start state\n",
    "    statereturn = []\n",
    "    while not done:\n",
    "        \n",
    "        validmoves = validMoves(state)\n",
    "        for m in validmoves:\n",
    "            Qs = np.array([Q.get(stateMoveTuple(state, m), 0) for m in validmoves]) \n",
    "        move = validmoves[np.argmax(Qs)]    \n",
    "        newstate = makeMove(state, move)\n",
    "        statereturn.append(newstate)\n",
    "        if winner(newstate):\n",
    "            done = True\n",
    "        state = newstate\n",
    "    return statereturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "Q, stepsToGoal = trainQ(50, 0.5, 0.7, validMoves, makeMove)\n",
    "print(len(Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = testQ(Q, 20, validMoves, makeMove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[2, 3], [], [1]],\n",
       " [[3], [2], [1]],\n",
       " [[3], [1, 2], []],\n",
       " [[], [1, 2], [3]],\n",
       " [[1], [2], [3]],\n",
       " [[1], [], [2, 3]],\n",
       " [[], [], [1, 2, 3]]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
